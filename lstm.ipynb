{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train csv num: 706\n",
      "val csv num: 78\n"
     ]
    }
   ],
   "source": [
    "# # TRAIN_FILES = '/home/dataset/training*/*/data_smooth.csv'\n",
    "# # TEST_FILES = '/home/dataset/validation*/*/data_smooth.csv'\n",
    "# BOX_PTS = 9\n",
    "# TRAIN_FILES = '/home/dataset/team2/training/training*/*_smooth_{}.csv'.format(BOX_PTS)\n",
    "# TEST_FILES = '/home/dataset/team2/validation/validation*/*_smooth_{}.csv'.format(BOX_PTS)\n",
    "    \n",
    "\n",
    "# train_csvs = glob.glob(TRAIN_FILES)\n",
    "\n",
    "# val_ratio = 0.1\n",
    "# train_csv_num = len(train_csvs)\n",
    "\n",
    "# val_num = int(train_csv_num * val_ratio)\n",
    "# train_num = train_csv_num - val_num\n",
    "\n",
    "# random.shuffle(train_csvs)\n",
    "\n",
    "# split_train_csvs = train_csvs[:train_num]\n",
    "# val_csvs = train_csvs[train_num:]\n",
    "# train_csvs = split_train_csvs\n",
    "\n",
    "# # print(train_csvs)\n",
    "# # print(val_csvs)\n",
    "# print('train csv num:', len(train_csvs))\n",
    "# print('val csv num:', len(val_csvs))\n",
    "\n",
    "# test_csvs = glob.glob(TEST_FILES)\n",
    "# test_num = len(test_csvs)\n",
    "# # print(test_csvs)\n",
    "# print('test csv num:', len(test_csvs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train csv num: 80\n",
      "val csv num: 8\n",
      "test csv num: 39\n"
     ]
    }
   ],
   "source": [
    "# use only car following\n",
    "train_csvs = []\n",
    "test_csvs = []\n",
    "BOX_PTS = 9\n",
    "\n",
    "file_list_path = '/home/dataset/urban_no_lane_changing_car_following.csv'\n",
    "fl = pd.read_csv(file_list_path, header=None).values\n",
    "for f in fl:\n",
    "    file_name = f[0]\n",
    "    if 'validation' in file_name:\n",
    "        test_csvs.append(f[0] + '_smooth_{}.csv'.format(BOX_PTS))\n",
    "    else:\n",
    "        train_csvs.append(f[0] + '_smooth_{}.csv'.format(BOX_PTS))\n",
    "        \n",
    "file_list_path = '/home/dataset/highway_no_lane_changing_car_following.csv'\n",
    "fl = pd.read_csv(file_list_path, header=None).values\n",
    "for f in fl:\n",
    "    file_name = f[0]\n",
    "    if 'validation' in file_name:\n",
    "        test_csvs.append(f[0] + '_smooth_{}.csv'.format(BOX_PTS))\n",
    "    else:\n",
    "        train_csvs.append(f[0] + '_smooth_{}.csv'.format(BOX_PTS))\n",
    "\n",
    "val_ratio = 0.1\n",
    "train_csv_num = len(train_csvs)\n",
    "\n",
    "val_num = int(train_csv_num * val_ratio)\n",
    "train_num = train_csv_num - val_num\n",
    "\n",
    "random.shuffle(train_csvs)\n",
    "\n",
    "split_train_csvs = train_csvs[:train_num]\n",
    "val_csvs = train_csvs[train_num:]\n",
    "train_csvs = split_train_csvs\n",
    "\n",
    "\n",
    "print('train csv num:', len(train_csvs))\n",
    "print('val csv num:', len(val_csvs))\n",
    "\n",
    "test_num = len(test_csvs)\n",
    "print('test csv num:', len(test_csvs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frame = 200\n",
    "dim_input = 12\n",
    "\n",
    "output_dim = max_frame * 3\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 300\n",
    "n_hidden = 256\n",
    "\n",
    "model_name = 'triple_lstm_epoch_{}_hidden_{}_car_following'.format(epochs, n_hidden)\n",
    "\n",
    "def build_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.LSTM(n_hidden,return_sequences=True, dropout=0.25,recurrent_dropout=0.1,input_shape=(max_frame ,dim_input)))\n",
    "    model.add(layers.LSTM(n_hidden, return_sequences=True, dropout=0.25,recurrent_dropout=0.1))\n",
    "    model.add(layers.LSTM(n_hidden, return_sequences=False, dropout=0.25,recurrent_dropout=0.1))\n",
    "    model.add(layers.Dense(output_dim))\n",
    "#     adam = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file not exists:  /home/dataset/team2/training/training_0025/training_0025_segment-5835049423600303130_180_000_200_000_smooth_9.csv\n",
      "file not exists:  /home/dataset/team2/training/training_0025/training_0025_segment-574762194520856849_1660_000_1680_000_smooth_9.csv\n",
      "file not exists:  /home/dataset/team2/training/training_0025/training_0025_segment-5871373218498789285_3360_000_3380_000_smooth_9.csv\n",
      "file not exists:  /home/dataset/team2/training/training_0025/training_0025_segment-6104545334635651714_2780_000_2800_000_smooth_9.csv\n",
      "file not exists:  /home/dataset/team2/validation/validation_0002/validation_0002_segment-13336883034283882790_7100_000_7120_000_smooth_9.csv\n",
      "file not exists:  /home/dataset/team2/validation/validation_0002/validation_0002_segment-13415985003725220451_6163_000_6183_000_smooth_9.csv\n",
      "file not exists:  /home/dataset/team2/validation/validation_0003/validation_0003_segment-16979882728032305374_2719_000_2739_000_smooth_9.csv\n",
      "file not exists:  /home/dataset/team2/validation/validation_0004/validation_0004_segment-2506799708748258165_6455_000_6475_000_smooth_9.csv\n",
      "train X:  (76, 200, 12)\n",
      "train y:  (76, 600)\n",
      "test X:  (35, 200, 12)\n",
      "test y:  (35, 600)\n",
      "val X:  (8, 200, 12)\n",
      "val y:  (8, 600)\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "for file in train_csvs:\n",
    "    try:\n",
    "        raw = pd.read_csv(file).values\n",
    "        length = raw.shape[0]\n",
    "        padding = np.zeros((max_frame, dim_input + 3))\n",
    "        padding[:length, :] = raw\n",
    "        train_data.append(padding)\n",
    "    except:\n",
    "        print('file not exists: ',file)\n",
    "    \n",
    "train_data = np.array(train_data)\n",
    "\n",
    "train_X = train_data[:,:,:-3]\n",
    "train_y = train_data[:,:,-3:]\n",
    "train_y = train_y.reshape(-1, output_dim)\n",
    "\n",
    "\n",
    "test_data = []\n",
    "for file in test_csvs:\n",
    "    try:\n",
    "        raw = pd.read_csv(file).values\n",
    "        length = raw.shape[0]\n",
    "        padding = np.zeros((max_frame, dim_input + 3))\n",
    "        padding[:length, :] = raw\n",
    "        test_data.append(padding)\n",
    "    except:\n",
    "        print('file not exists: ', file)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_X = test_data[:, :, :-3]\n",
    "test_y = test_data[:, :, -3:]\n",
    "test_y = test_y.reshape(-1, output_dim)\n",
    "\n",
    "val_data = []\n",
    "for file in val_csvs:\n",
    "    try:\n",
    "        raw = pd.read_csv(file).values\n",
    "        length = raw.shape[0]\n",
    "        padding = np.zeros((max_frame, dim_input + 3))\n",
    "        padding[:length, :] = raw\n",
    "        val_data.append(padding)\n",
    "    except:\n",
    "        print('file not exists: ', file)\n",
    "\n",
    "val_data = np.array(val_data)\n",
    "val_X = val_data[:, :, :-3]\n",
    "val_y = val_data[:, :, -3:]\n",
    "val_y = val_y.reshape(-1, output_dim)\n",
    "\n",
    "\n",
    "print(\"train X: \", train_X.shape)\n",
    "print(\"train y: \", train_y.shape)\n",
    "\n",
    "print(\"test X: \", test_X.shape)\n",
    "print(\"test y: \", test_y.shape)\n",
    "\n",
    "print(\"val X: \", val_X.shape)\n",
    "print(\"val y: \", val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zg2309/anaconda3/envs/waymo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 200, 256)          275456    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200, 256)          525312    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 600)               154200    \n",
      "=================================================================\n",
      "Total params: 1,480,280\n",
      "Trainable params: 1,480,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /home/zg2309/anaconda3/envs/waymo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 76 samples, validate on 8 samples\n",
      "Epoch 1/300\n",
      "76/76 [==============================] - 9s 116ms/sample - loss: 0.1446 - val_loss: 0.1027\n",
      "Epoch 2/300\n",
      "76/76 [==============================] - 4s 50ms/sample - loss: 0.1387 - val_loss: 0.1028\n",
      "Epoch 3/300\n"
     ]
    }
   ],
   "source": [
    "# Aggregated Training Error\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_X, train_y, validation_data=(val_X, val_y), batch_size=batch_size, epochs=epochs, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "fig = plt.gcf()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "fig.savefig('/home/zg2309/history/{}'.format(model_name))\n",
    "plt.close(fig)\n",
    "\n",
    "score = model.evaluate(test_X, test_y, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save(\"/home/zg2309/model/{}.h5\".format(model_name))\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
