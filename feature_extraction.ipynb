{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zg2309/anaconda3/envs/waymo/lib/python3.6/site-packages/waymo_open_dataset/utils/range_image_utils.py:59: The name tf.unsorted_segment_max is deprecated. Please use tf.math.unsorted_segment_max instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/zg2309/anaconda3/envs/waymo/lib/python3.6/site-packages/waymo_open_dataset/utils/range_image_utils.py:226: The name tf.unsorted_segment_min is deprecated. Please use tf.math.unsorted_segment_min instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "from waymo_open_dataset.utils import range_image_utils\n",
    "from waymo_open_dataset.utils import transform_utils\n",
    "from waymo_open_dataset.utils import  frame_utils\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "\n",
    "\n",
    "# tar_name = 'training_0010'\n",
    "# files_path = '/home/zg2309/data/training/{}/'.format(tar_name)\n",
    "\n",
    "tar_name = 'validation_0007'\n",
    "files_path = '/home/zg2309/data/validation/{}/'.format(tar_name)\n",
    "\n",
    "files = glob.glob(files_path + \"*.tfrecord\")\n",
    "print(len(files))\n",
    "\n",
    "# For visualization: https://drive.google.com/drive/u/0/folders/1-CXDJwgd96fTHHboekfdyIxVj2lzjf1n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon, LineString\n",
    "\n",
    "def intersects(label):\n",
    "  # Starting from the upper-left corner, clock direction\n",
    "  bounding_box = Polygon([\n",
    "      (label.box.center_x - 0.5 * label.box.length, label.box.center_y + 0.5 * label.box.width), \n",
    "      (label.box.center_x + 0.5 * label.box.length, label.box.center_y - 0.5 * label.box.width), \n",
    "      (label.box.center_x + 0.5 * label.box.length, label.box.center_y + 0.5 * label.box.width),\n",
    "      (label.box.center_x - 0.5 * label.box.length, label.box.center_y - 0.5 * label.box.width)\n",
    "  ])\n",
    "  \n",
    "  line = LineString([(0, 0), (label.box.center_x, 0)])\n",
    "  \n",
    "  return bounding_box.intersects(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def find_corresponding_projected_lidar_label(frame, front_car_laser_label):\n",
    "    for pll_wrapper in frame.projected_lidar_labels:\n",
    "        if pll_wrapper.name != FRONT:\n",
    "            continue\n",
    "      \n",
    "    for pll in pll_wrapper.labels:\n",
    "        if front_car_laser_label.id in pll.id:\n",
    "            return pll\n",
    "      \n",
    "    return None\n",
    "\n",
    "def show_label_on_image(camera_image, label, layout, cmap=None):\n",
    "    \"\"\"Show a camera image and the given camera labels.\"\"\"\n",
    "    ax = plt.subplot(*layout)\n",
    "\n",
    "      # Draw the object bounding box.\n",
    "    ax.add_patch(patches.Rectangle(\n",
    "      xy=(label.box.center_x - 0.5 * label.box.length,\n",
    "          label.box.center_y - 0.5 * label.box.width),\n",
    "      width=label.box.length,\n",
    "      height=label.box.width,\n",
    "      linewidth=1,\n",
    "      edgecolor='red',\n",
    "      facecolor='none'))\n",
    "\n",
    "  # Show the camera image.\n",
    "    plt.imshow(tf.image.decode_jpeg(camera_image.image), cmap=cmap)\n",
    "    plt.title(open_dataset.CameraName.Name.Name(camera_image.name))\n",
    "    plt.grid(False)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.figure(figsize=(25, 20))\n",
    "    \n",
    "def verify_front_car_label(frame, front_car_label):\n",
    "    \"\"\"\n",
    "    Display the bounding box of the found front car on the image to verify if the \n",
    "    front car is captured correctly.\n",
    "    \"\"\"\n",
    "    for index, image in enumerate(frame.images):\n",
    "        front_car_pll = find_corresponding_projected_lidar_label(frame, front_car_label)\n",
    "        if front_car_pll is not None:\n",
    "            show_label_on_image(image, front_car_pll, [3, 3, index + 1])\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def collect_vehicle_laser_labels(frame):\n",
    "    # only return label.type equal vehicle\n",
    "    #TYPE_VEHICLE = 1\n",
    "    return [data for data in frame.laser_labels if data.type == 1]\n",
    "\n",
    "def get_front_car_laser_label(labels):\n",
    "    \"\"\"\n",
    "    Find the closest bounding box which intersects with y = 0 and its center_x is positive\n",
    "    \"\"\"\n",
    "  \n",
    "    front_car_label = None\n",
    "    for label in labels:\n",
    "        if label.box.center_x < 0:\n",
    "            continue \n",
    "      \n",
    "        if intersects(label):\n",
    "            if front_car_label is None or front_car_label.box.center_x > label.box.center_x:\n",
    "                front_car_label = label\n",
    "      \n",
    "    return front_car_label\n",
    "\n",
    "\n",
    "def car_acceleration(v1, v2, dt):\n",
    "    return (v1 - v2) / dt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE_VEHICLE = 1\n",
    "FRONT = 0\n",
    "FPS = 10\n",
    "DT = 1.0 / FPS\n",
    "VERIFY_THRESHOLD = 0.05\n",
    "\n",
    "FRONTCAR_Y_THRESHOLD = 0.05\n",
    "\n",
    "\"\"\"\n",
    "features:\n",
    "[vx, vy, vz, dx, dy, vfx, vfy, vfz, afx, afy, afz]\n",
    "labels:\n",
    "[ax, ay, az]\n",
    "\"\"\"\n",
    "\n",
    "def write_to_csv(filename, feats, labels):\n",
    "    comb_np = np.hstack((feats, labels))\n",
    "    np.savetxt(filename, comb_np, delimiter=\",\")\n",
    "\n",
    "def get_vehicle_pose(frame):\n",
    "    # get front pose\n",
    "    front_image = frame.images[0]\n",
    "    pose = [t for t in front_image.pose.transform]\n",
    "    return np.asarray(pose).reshape((4,4))\n",
    "\n",
    "def get_current_car_velocity_wrt_GF(frame):\n",
    "    \"\"\"\n",
    "    Return the speed v_x, v_y, v_z of the current car\n",
    "    \"\"\"\n",
    "    image = frame.images[FRONT]\n",
    "    return np.asarray([image.velocity.v_x, image.velocity.v_y, image.velocity.v_z])\n",
    "\n",
    "def get_front_car_velocity_wrt_GF(front_car_label, vehicle_pose, v_cur_GF):\n",
    "    v_front_VF = np.asarray([front_car_label.metadata.speed_x, front_car_label.metadata.speed_y, 0])\n",
    "    _v_front_VF = np.hstack((v_front_VF, [0])) # padded 0 for matrix multiplication\n",
    "    return np.matmul(vehicle_pose, _v_front_VF)[:3] - v_cur_GF\n",
    "\n",
    "def get_relative_distance(front_car_label):\n",
    "    return np.asarray([front_car_label.box.center_x, front_car_label.box.center_y])\n",
    "\n",
    "def get_current_car_accel_GF_per_frame(dt, v_cur_GF, v_cur_GF_prev):\n",
    "    return car_acceleration(v_cur_GF, v_cur_GF_prev, dt) if v_cur_GF_prev is not None else np.asarray([0, 0, 0])\n",
    "\n",
    "def get_front_car_GF_features_per_frame(dt, frame, vehicle_pose, front_car_label,\n",
    "                                        v_cur_GF, v_front_GF_prev, verify=False):\n",
    "\n",
    "    if verify and random.random() < VERIFY_THRESHOLD:\n",
    "        verify_front_car_label(frame, front_car_label)\n",
    "\n",
    "    relative_dist = get_relative_distance(front_car_label) # 2 * 1\n",
    "    v_front_GF = get_front_car_velocity_wrt_GF(front_car_label, vehicle_pose, v_cur_GF) # 3 * 1\n",
    "    a_front_GF = car_acceleration(v_front_GF, v_front_GF_prev, dt) if v_front_GF_prev is not None else np.asarray([0, 0, 0]) # 3 * 1\n",
    "\n",
    "    return np.hstack((relative_dist, v_front_GF, a_front_GF)), v_front_GF\n",
    "\n",
    "\n",
    "def get_essentials_per_frame(dt, frame, front_car_label, v_cur_GF_prev, v_front_GF_prev):\n",
    "    vehicle_pose = get_vehicle_pose(frame)\n",
    "    v_cur_GF = get_current_car_velocity_wrt_GF(frame) # 3 * 1\n",
    "    front_GF_feat, v_front_GF = get_front_car_GF_features_per_frame(DT, frame, vehicle_pose, front_car_label,\n",
    "                                                                  v_cur_GF, v_front_GF_prev) # 8 * 1\n",
    "    a_cur_GF = get_current_car_accel_GF_per_frame(dt, v_cur_GF, v_cur_GF_prev) # 3 * 1\n",
    "\n",
    "    return np.hstack((v_cur_GF, front_GF_feat)), a_cur_GF, v_cur_GF, v_front_GF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_labels(frames):\n",
    "    feat_set = []\n",
    "    label_set = []\n",
    "    \n",
    "    # init\n",
    "    v_cur_GF_prev = None\n",
    "    v_front_GF_prev = None\n",
    "\n",
    "    for frame in frames:\n",
    "        # Capture the front car\n",
    "        v_laser_labels = collect_vehicle_laser_labels(frame)\n",
    "        front_car_label = get_front_car_laser_label(v_laser_labels)\n",
    "\n",
    "        if front_car_label is not None:\n",
    "            feats, labels, v_cur_GF_prev, v_front_GF_prev = get_essentials_per_frame(DT, frame, front_car_label, v_cur_GF_prev, v_front_GF_prev)\n",
    "        else:\n",
    "            #if there is no front car\n",
    "            v_cur_GF = get_current_car_velocity_wrt_GF(frame)\n",
    "            vx, vy, vz = v_cur_GF\n",
    "            feats = [vx, vy, vz, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "            ax, ay, az = [0,0,0]\n",
    "            \n",
    "            if v_cur_GF_prev is not None:\n",
    "                ax, ay, az = get_current_car_accel_GF_per_frame(DT, v_cur_GF, v_cur_GF_prev)\n",
    "            labels = [ax, ay, az]\n",
    "            \n",
    "            v_cur_GF_prev = v_cur_GF\n",
    "            v_front_GF_prev = None\n",
    "            \n",
    "        feat_set.append(feats)\n",
    "        label_set.append(labels)\n",
    "        \n",
    "        \n",
    "    # fix first frame acceleration [0,0,0]\n",
    "    if np.sum(np.abs(label_set[0])) == 0:\n",
    "        label_set[0] = label_set[1]\n",
    "        \n",
    "    return np.asarray(feat_set), np.asarray(label_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visualization(folder_name, feats, labels, smooth_feats, smooth_labels):    \n",
    "    VX = 0\n",
    "    VY = 1\n",
    "    VZ = 2\n",
    "    DX = 3\n",
    "    DY = 4\n",
    "    VFX = 5\n",
    "    VFY = 6\n",
    "    VFZ = 7\n",
    "    AFX = 8\n",
    "    AFY = 9\n",
    "    AFZ = 10\n",
    "\n",
    "    AX = 0\n",
    "    AY = 1\n",
    "\n",
    "    times = [t * DT for t in range(0, len(feats))] \n",
    " \n",
    "    fig1, ax1 = plt.subplots()\n",
    "    \n",
    "    dxs = [f[DX] for f in feats]\n",
    "    ax1.plot(times, dxs, label='origin')\n",
    "    \n",
    "    dxss = [f[DX] for f in smooth_feats]\n",
    "    ax1.plot(times, dxss, label=\"smooth\")\n",
    "    \n",
    "    ax1.set_ylabel('relative distance along x')\n",
    "    ax1.set_xlabel('time')\n",
    "    fig1.savefig(folder_name + 'relative_distance_x.png')\n",
    "    \n",
    "    fig2, ax2 = plt.subplots()\n",
    "    \n",
    "    dys = [f[DY] for f in feats]\n",
    "    ax2.plot(times, dys, label='origin')\n",
    "    \n",
    "    dyss = [f[DY] for f in smooth_feats]\n",
    "    ax2.plot(times, dyss, label=\"smooth\")\n",
    "    \n",
    "    ax2.set_ylabel('relative distance along y')\n",
    "    ax2.set_xlabel('time')\n",
    "    fig2.savefig(folder_name + 'relative_distance_y.png')\n",
    "\n",
    "    fig3, ax3 = plt.subplots()\n",
    "    \n",
    "    afxs = [f[AFX] for f in feats]\n",
    "    ax3.plot(times, afxs, label='origin')\n",
    "    \n",
    "    afxss = [f[AFX] for f in smooth_feats]\n",
    "    ax3.plot(times, afxss, label=\"smooth\")\n",
    "    \n",
    "    ax3.set_ylabel('accel x of front car')\n",
    "    ax3.set_xlabel('time')\n",
    "    fig3.savefig(folder_name + 'accel_x_front_car.png')\n",
    "\n",
    "    fig4, ax4 = plt.subplots()\n",
    "    \n",
    "    afys = [f[AFY] for f in feats]\n",
    "    ax4.plot(times, afys, label='origin')\n",
    "    \n",
    "    afyss = [f[AFY] for f in smooth_feats]\n",
    "    ax4.plot(times, afyss, label=\"smooth\")\n",
    "    \n",
    "    ax4.set_ylabel('accel y of front car')\n",
    "    ax4.set_xlabel('time')\n",
    "    fig4.savefig(folder_name + 'accel_y_front_car.png')\n",
    "\n",
    "    # For verification\n",
    "    fig5, ax5 = plt.subplots()\n",
    "    \n",
    "    vfxs = [f[VFX] for f in feats]\n",
    "    ax5.plot(times, vfxs, label='origin')\n",
    "    \n",
    "#     vfxss = [f[VFX] for f in smooth_feats]\n",
    "#     ax5.plot(times, vfxss, label=\"smooth\")\n",
    "    \n",
    "    ax5.set_ylabel('speed x of front car')\n",
    "    ax5.set_xlabel('time')\n",
    "    fig5.savefig(folder_name + 'speed_x_front_car.png')\n",
    "\n",
    "    fig6, ax6 = plt.subplots()\n",
    "    \n",
    "    vfys = [f[VFY] for f in feats]\n",
    "    ax6.plot(times, vfys, label='origin')\n",
    "    \n",
    "#     vfyss = [f[VFY] for f in smooth_feats]\n",
    "#     ax6.plot(times, vfyss, label=\"smooth\")\n",
    "    \n",
    "    ax6.set_ylabel('speed y of front car')\n",
    "    ax6.set_xlabel('time')\n",
    "    fig6.savefig(folder_name + 'speed_y_front_car.png')\n",
    "\n",
    "    fig7, ax7 = plt.subplots()\n",
    "    \n",
    "    axs = [l[AX] for l in labels]\n",
    "    ax7.plot(times, axs, label=\"origin\")\n",
    "    \n",
    "    axss = [l[AX] for l in smooth_labels]\n",
    "    ax7.plot(times, axss, label=\"smooth\")\n",
    "    ax7.set_ylabel('accel x of current car')\n",
    "    ax7.set_xlabel('time')\n",
    "    fig7.savefig(folder_name + 'accel_x_current_car.png')\n",
    "\n",
    "    fig8, ax8 = plt.subplots()\n",
    "    \n",
    "    ays = [l[AY] for l in labels]\n",
    "    ax8.plot(times, ays, label=\"origin\")\n",
    "    ayss = [l[AY] for l in smooth_labels]\n",
    "    \n",
    "    ax8.plot(times, ayss, label=\"smooth\")\n",
    "    ax8.set_ylabel('accel y of current car')\n",
    "    ax8.set_xlabel('time')\n",
    "    fig8.savefig(folder_name + 'accel_y_current_car.png')\n",
    "\n",
    "    fig9, ax9 = plt.subplots()\n",
    "    \n",
    "    vxs = [f[VX] for f in feats]\n",
    "    ax9.plot(times, vxs, label='origin')\n",
    "    \n",
    "#     vxss = [f[VX] for f in smooth_feats]\n",
    "#     ax9.plot(times, vxss, label=\"smooth\")\n",
    "    \n",
    "    ax9.set_ylabel('speed x of current car')\n",
    "    ax9.set_xlabel('time')\n",
    "    fig9.savefig(folder_name + 'speed_x_current_car.png')\n",
    "\n",
    "    fig10, ax10 = plt.subplots()\n",
    "    \n",
    "    vys = [f[VY] for f in feats]\n",
    "    ax10.plot(times, vys, label='origin')\n",
    "    \n",
    "#     vyss = [f[VY] for f in smooth_feats]\n",
    "#     ax10.plot(times, vyss, label=\"smooth\")\n",
    "    \n",
    "    ax10.set_ylabel('speed y of current car')\n",
    "    ax10.set_xlabel('time')\n",
    "    fig10.savefig(folder_name + 'speed_y_current_car.png')\n",
    "    \n",
    "    plt.close(fig1)\n",
    "    plt.close(fig2)\n",
    "    plt.close(fig3)\n",
    "    plt.close(fig4)\n",
    "    plt.close(fig5)\n",
    "    plt.close(fig6)\n",
    "    plt.close(fig7)\n",
    "    plt.close(fig8)\n",
    "    plt.close(fig9)\n",
    "    plt.close(fig10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "FRONT = 0 # front view\n",
    "TYPE_VEHICLE = 1\n",
    "TYPE_PEDESTRIAN = 2\n",
    "TYPE_SIGN = 3\n",
    "TYPE_CYCLIST = 4\n",
    "\n",
    "def video_generation(folder, frames):\n",
    "    imgs = []\n",
    "\n",
    "    for frame in frames:\n",
    "        image = frame.images[FRONT]\n",
    "        img = tf.image.decode_jpeg(image.image)\n",
    "        imgs.append(img.numpy())\n",
    "    \n",
    "    img = imgs[0]\n",
    "    height, width, _ = img.shape\n",
    "    size = (width, height)\n",
    "    out_video = folder + 'video.mp4'\n",
    "    fps = 10\n",
    "    \n",
    "    out = cv2.VideoWriter(out_video, cv2.VideoWriter_fourcc(*'XVID'), fps, size)\n",
    "    \n",
    "    for img in imgs:\n",
    "        gbr = img[...,::-1].copy()\n",
    "        out.write(gbr)\n",
    "    out.release()\n",
    "\n",
    "def add_label_to_camera_image(camera_image, camera_labels):\n",
    "    \n",
    "    # convert rgb array to opencv's bgr format\n",
    "    im_arr_bgr = cv2.cvtColor(camera_image, cv2.COLOR_RGB2BGR)\n",
    "    for label in camera_labels:\n",
    "        # Draw the object bounding box.\n",
    "        lt = label.type\n",
    "        #bgr\n",
    "        if lt == TYPE_VEHICLE:\n",
    "            #blue\n",
    "            ec = (0,0,255)\n",
    "        elif lt == TYPE_PEDESTRIAN:\n",
    "            ec = (0,255,0)\n",
    "        elif lt == TYPE_SIGN:\n",
    "            ec = (255,255,255)\n",
    "        elif lt == TYPE_CYCLIST:\n",
    "            ec = (255,0,0)\n",
    "        \n",
    "        pts1 = (int(label.box.center_x - 0.5 * label.box.length), int(label.box.center_y - 0.5 * label.box.width))\n",
    "        pts2 = (int(label.box.center_x + 0.5 * label.box.length), int(label.box.center_y + 0.5 * label.box.width))\n",
    "\n",
    "        cv2.rectangle(im_arr_bgr, pts1, pts2, ec, 1)\n",
    "    \n",
    "    im_arr = cv2.cvtColor(im_arr_bgr, cv2.COLOR_BGR2RGB)\n",
    "    return im_arr\n",
    "    \n",
    "def video_generation_with_label(folder, frames):\n",
    "    imgs = []\n",
    "\n",
    "    for frame in frames:\n",
    "        image = frame.images[FRONT]\n",
    "        img = tf.image.decode_jpeg(image.image).numpy()\n",
    "        labels = frame.projected_lidar_labels[FRONT].labels\n",
    "        if len(labels) > 0:\n",
    "            img = add_label_to_camera_image(img, labels)\n",
    "        imgs.append(img)\n",
    "    \n",
    "    img = imgs[0]\n",
    "    height, width, _ = img.shape\n",
    "    size = (width, height)\n",
    "    out_video = folder + 'video_label.mp4'\n",
    "    fps = 10\n",
    "    \n",
    "    out = cv2.VideoWriter(out_video, cv2.VideoWriter_fourcc(*'XVID'), fps, size)\n",
    "    \n",
    "    for img in imgs:\n",
    "        gbr = img[...,::-1].copy()\n",
    "        out.write(gbr)\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: /home/zg2309/data/validation/validation_0007/segment-9114112687541091312_1100_000_1120_000.tfrecord Num of frames: 198\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-7988627150403732100_1487_540_1507_540.tfrecord Num of frames: 199\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-8079607115087394458_1240_000_1260_000.tfrecord Num of frames: 198\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-8679184381783013073_7740_000_7760_000.tfrecord Num of frames: 198\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-8133434654699693993_1162_020_1182_020.tfrecord Num of frames: 199\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-8907419590259234067_1960_000_1980_000.tfrecord Num of frames: 198\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-9443948810903981522_6538_870_6558_870.tfrecord Num of frames: 199\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-9231652062943496183_1740_000_1760_000.tfrecord Num of frames: 198\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-7799643635310185714_680_000_700_000.tfrecord Num of frames: 199\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-8956556778987472864_3404_790_3424_790.tfrecord Num of frames: 198\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-8398516118967750070_3958_000_3978_000.tfrecord Num of frames: 199\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-7932945205197754811_780_000_800_000.tfrecord Num of frames: 198\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-933621182106051783_4160_000_4180_000.tfrecord Num of frames: 198\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-8137195482049459160_3100_000_3120_000.tfrecord Num of frames: 199\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-89454214745557131_3160_000_3180_000.tfrecord Num of frames: 199\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-9265793588137545201_2981_960_3001_960.tfrecord Num of frames: 198\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-9472420603764812147_850_000_870_000.tfrecord Num of frames: 198\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-9041488218266405018_6454_030_6474_030.tfrecord Num of frames: 199\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-967082162553397800_5102_900_5122_900.tfrecord Num of frames: 199\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-9579041874842301407_1300_000_1320_000.tfrecord Num of frames: 199\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-9024872035982010942_2578_810_2598_810.tfrecord Num of frames: 198\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-9164052963393400298_4692_970_4712_970.tfrecord Num of frames: 199\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-9243656068381062947_1297_428_1317_428.tfrecord Num of frames: 198\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-8331804655557290264_4351_740_4371_740.tfrecord Num of frames: 199\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-8302000153252334863_6020_000_6040_000.tfrecord Num of frames: 199\n",
      "filename: /home/zg2309/data/validation/validation_0007/segment-8506432817378693815_4860_000_4880_000.tfrecord Num of frames: 198\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "RESULT_PATH = '/home/zg2309/result/{}/'.format(tar_name)\n",
    "\n",
    "if os.path.exists(RESULT_PATH):\n",
    "    shutil.rmtree(RESULT_PATH)\n",
    "os.mkdir(RESULT_PATH)\n",
    "\n",
    "for i in range(len(files)):\n",
    "    file = files[i]\n",
    "    dataset = tf.data.TFRecordDataset(file, compression_type='')\n",
    "    \n",
    "    # Load frames from dataset\n",
    "    frames = []\n",
    "    for data in dataset:\n",
    "        frame = open_dataset.Frame()\n",
    "        frame.ParseFromString(bytearray(data.numpy()))\n",
    "        frames.append(frame)\n",
    "        \n",
    "    \n",
    "#     print(collect_vehicle_laser_labels(frames[0])[0])\n",
    "#     break\n",
    "    print(\"filename:\", file, \"Num of frames:\", len(frames))\n",
    "        \n",
    "    file_name = file.split('/')[-1].split('.')[0]\n",
    "    save_folder = RESULT_PATH + file_name + '/'\n",
    "    os.mkdir(save_folder)\n",
    "    \n",
    "    feats, labels = get_features_and_labels(frames)\n",
    "\n",
    "    write_to_csv(save_folder + 'data.csv', feats, labels)\n",
    "    \n",
    "    # smooth only acceleration!\n",
    "    box_pts = 5\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    \n",
    "    smooth_feats = np.array(feats).copy()\n",
    "    \n",
    "#    DX = 3\n",
    "#     DY = 4\n",
    "#     AFX = 8\n",
    "#     AFY = 9\n",
    "#     AFZ = 10\n",
    "    smooth_feats_idx = [3,4,8,9,10]\n",
    "    \n",
    "    for i in smooth_feats_idx:\n",
    "        smooth_feats[:,i] = np.convolve(smooth_feats[:,i], box, mode='same')\n",
    "    \n",
    "    smooth_labels = np.array(labels).copy()\n",
    "    _, label_num = smooth_labels.shape\n",
    "    \n",
    "    for i in range(label_num):\n",
    "        smooth_labels[:,i] = np.convolve(smooth_labels[:,i], box, mode='same')\n",
    "    \n",
    "    write_to_csv(save_folder + 'data_smooth.csv', smooth_feats, smooth_labels)\n",
    "\n",
    "    visualization(save_folder, feats, labels, smooth_feats, smooth_labels)\n",
    "    \n",
    "    video_generation(save_folder, frames)\n",
    "    video_generation_with_label(save_folder, frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
